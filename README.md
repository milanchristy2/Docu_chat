# DocuChat - RAG-Based Question Answering System

A Retrieval-Augmented Generation (RAG) system that enables users to upload documents (PDF or text files) and interact with them conversationally using a Large Language Model (LLM).

---

## Features

- ğŸ“„ **Document Upload** - Upload PDF or text files
- ğŸ’¬ **Conversational QA** - Chat with your documents using natural language
- ğŸ” **Semantic Search** - Retrieve relevant document chunks using embeddings
- ğŸ§  **AI-Powered Answers** - Generate context-aware responses using LLM
- ğŸ“Š **Evaluation Metrics** - Track faithfulness, answer relevancy, context precision, and recall
- ğŸ—„ï¸ **Chat History** - Persistent conversation storage

---

## Technology Stack

### Backend
- **Framework**: FastAPI
- **Database**: SQLAlchemy ORM with SQLite/PostgreSQL
- **Migrations**: Alembic
- **AI/LLM**: LangChain, Ollama (llama3.2-vision:latest)
- **Embeddings**: Ollama (mxbai-embed-large)
- **Vector Store**: FAISS / ChromaDB

### Frontend
- **Framework**: React 19
- **Build Tool**: Vite
- **Styling**: Bootstrap 5
- **HTTP Client**: Axios

---

## Prerequisites

Before running the project, ensure you have:

1. **Python 3.10+** installed
2. **Node.js 18+** installed
3. **Ollama** installed and running locally

### Install Ollama

```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# Start Ollama service
ollama serve

# Pull required models (in a new terminal)
ollama pull llama3.2-vision:latest
ollama pull mxbai-embed-large
```

---

## Project Setup

### 1. Clone the Repository

```bash
cd /Users/milanchristy/Desktop/Docu_chat
```

### 2. Backend Setup

#### Create Virtual Environment

```bash
# Create virtual environment
python -m venv venv

# Activate on macOS/Linux
source venv/bin/activate

# Activate on Windows
venv\Scripts\activate
```

#### Install Python Dependencies

```bash
pip install -r requirements.txt
```

#### Environment Configuration

Create a `.env` file in the project root:

```env
# Database (use SQLite for development, PostgreSQL for production)
DATABASE_URL=sqlite:///./rag.db

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
LLAMA_MODEL=llama3.2-vision:latest
EMBEDDING_MODEL=mxbai-embed-large

# Vector Store Configuration
VECTOR_STORE_TYPE=faiss  # or chromadb
```

#### Run Database Migrations

```bash
cd /Users/milanchristy/Desktop/Docu_chat
alembic upgrade head
```

#### Start the Backend Server

```bash
# From project root
python -m backend.src.app.main
```

The backend will run at: **http://localhost:8000**

---

### 3. Frontend Setup

#### Navigate to Frontend Directory

```bash
cd /Users/milanchristy/Desktop/Docu_chat/frontend
```

#### Install Dependencies

```bash
npm install
```

#### Start the Frontend Development Server

```bash
npm run dev
```

The frontend will run at: **http://localhost:5173**

---

## Running the Application

### Option 1: Development Mode

1. **Start Ollama** (in a terminal):
   ```bash
   ollama serve
   ```

2. **Start Backend** (in a new terminal):
   ```bash
   cd /Users/milanchristy/Desktop/Docu_chat
   source venv/bin/activate
   python -m backend.src.app.main
   ```

3. **Start Frontend** (in another terminal):
   ```bash
   cd /Users/milanchristy/Desktop/Docu_chat/frontend
   npm run dev
   ```

4. Open browser: **http://localhost:5173**

### Option 2: Production Build

```bash
# Build frontend
cd /Users/milanchristy/Desktop/Docu_chat/frontend
npm run build

# Serve the build (using any static file server)
npm run preview
```

---

## API Endpoints

### Document Upload
```
POST /documents/upload/
Content-Type: multipart/form-data
Body: file (PDF or text file)
```

### Query/Chat
```
POST /query/
Content-Type: application/json
Body: {
  "chat_id": "uuid-string",
  "content": "Your question here"
}
```

### Create New Chat
```
POST /chats/
Content-Type: application/json
Body: {
  "user_id": "user-identifier"
}
```

### Get Chat History
```
GET /chats/{chat_id}/messages
```

---

## Project Structure

```
Docu_chat/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ app/
â”‚           â”œâ”€â”€ api/
â”‚           â”‚   â””â”€â”€ routes/
â”‚           â”‚       â”œâ”€â”€ chat_router.py
â”‚           â”‚       â”œâ”€â”€ query_router.py
â”‚           â”‚       â””â”€â”€ upload_router.py
â”‚           â”œâ”€â”€ core/
â”‚           â”‚   â””â”€â”€ config.py
â”‚           â”œâ”€â”€ database/
â”‚           â”‚   â””â”€â”€ session.py
â”‚           â”œâ”€â”€ models/
â”‚           â”‚   â””â”€â”€ db_models.py
â”‚           â”œâ”€â”€ rag/
â”‚           â”‚   â”œâ”€â”€ ingest_documents.py
â”‚           â”‚   â”œâ”€â”€ rag_chain.py
â”‚           â”‚   â””â”€â”€ retriever.py
â”‚           â”œâ”€â”€ schemas/
â”‚           â”‚   â””â”€â”€ schemas.py
â”‚           â”œâ”€â”€ services/
â”‚           â”‚   â”œâ”€â”€ chat_service.py
â”‚           â”‚   â”œâ”€â”€ document_service.py
â”‚           â”‚   â””â”€â”€ evaluation_service.py
â”‚           â””â”€â”€ utils/
â”‚               â”œâ”€â”€ document_loader.py
â”‚               â”œâ”€â”€ prompt_template.py
â”‚               â””â”€â”€ text_splitter.py
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.jsx
â”‚   â”‚   â”‚   â””â”€â”€ Upload.jsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ main.jsx
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ alembic/
â”‚   â””â”€â”€ versions/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ docu_chat-design.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

### Vector Store

Set in `.env`:
```env
VECTOR_STORE_TYPE=faiss  # or chromadb
```

### LLM Model

Set in `.env`:
```env
LLAMA_MODEL=llama3.2-vision:latest
```

---

## Troubleshooting

### Issue: Ollama not running
```bash
# Check if Ollama is running
ollama list

# If not, start it
ollama serve
```

### Issue: Database connection error
```bash
# Check DATABASE_URL in .env
# For SQLite, ensure the file path is correct

# Run migrations
alembic upgrade head
```

### Issue: Frontend can't connect to backend
- Ensure backend is running on http://localhost:8000
- Check CORS settings in `backend/src/app/main.py`
- Verify frontend API base URL in `frontend/src/services/api.js`

### Issue: Vector store errors
- Delete existing vector store: `backend/src/app/data/vector_store/`
- Re-upload documents to rebuild index

---

## Development Notes

- Files are stored locally in `backend/src/app/data/`
- Vector store is in `backend/src/app/data/vector_store/`
- Database is at `backend/src/app/database/rag.db`
- Use Alembic for database migrations: `alembic revision --autogenerate`

---


